"""
ç”³ä¸‡è¡Œä¸šæŒ‡æ•°å¸‚ç›ˆç‡å¸‚å‡€ç‡å†å²ç™¾åˆ†ä½åˆ†æè„šæœ¬ - sw_dailyç‰ˆ

ä½¿ç”¨Tushare sw_dailyæ¥å£ç›´æ¥è·å–ç”³ä¸‡è¡Œä¸šæŒ‡æ•°PE/PBæ•°æ®
éœ€è¦5000ç§¯åˆ†æƒé™

ä½¿ç”¨æ–¹æ³•:
    python industry_pe_pb_sw.py                    # é»˜è®¤ï¼šä¸€çº§è¡Œä¸šï¼Œ1å¹´å†å²
    python industry_pe_pb_sw.py --level L2         # äºŒçº§è¡Œä¸š
    python industry_pe_pb_sw.py --level L3         # ä¸‰çº§è¡Œä¸š
    python industry_pe_pb_sw.py --years 3          # 3å¹´å†å²
    python industry_pe_pb_sw.py --interval 10      # æ¯10å¤©é‡‡æ ·
"""

import tushare as ts
import pandas as pd
from datetime import datetime, timedelta
import time
import argparse
import os


# Tushare Token - æ”¯æŒç¯å¢ƒå˜é‡è‡ªå®šä¹‰
DEFAULT_TOKEN = '15bb21f848e2844fee6046746341f03079d4911b96fc80f1a48ee8da'
TOKEN = os.environ.get('TUSHARE_TOKEN', DEFAULT_TOKEN)

# APIé¢‘ç‡é™åˆ¶é…ç½®
REQUEST_INTERVAL = 0.3  # sw_dailyæ¥å£é¢‘ç‡é™åˆ¶è¾ƒå®½æ¾
RATE_LIMIT_WAIT = 65


class TushareAPI:
    """Tushare APIå°è£…ç±»"""
    
    def __init__(self, pro):
        self.pro = pro
        self.last_request_time = 0
        self.total_requests = 0
    
    def call_with_retry(self, api_func, api_name="æœªçŸ¥API", max_retries=5, **kwargs):
        """å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨"""
        for attempt in range(max_retries):
            try:
                elapsed = time.time() - self.last_request_time
                if elapsed < REQUEST_INTERVAL:
                    time.sleep(REQUEST_INTERVAL - elapsed)
                
                result = api_func(**kwargs)
                self.last_request_time = time.time()
                self.total_requests += 1
                
                return result
                
            except Exception as e:
                error_msg = str(e)
                
                if "æ¯åˆ†é’Ÿæœ€å¤šè®¿é—®" in error_msg or "è®¿é—®è¿‡äºé¢‘ç¹" in error_msg:
                    print(f"âš ï¸  è§¦å‘é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾…{RATE_LIMIT_WAIT}ç§’...")
                    time.sleep(RATE_LIMIT_WAIT)
                    continue
                
                print(f"âŒ APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {error_msg}")
                time.sleep(2)
        
        return None


def get_industry_list(api, level='L1'):
    """
    è·å–ç”³ä¸‡è¡Œä¸šåˆ—è¡¨
    
    å‚æ•°:
        api: TushareAPIå®ä¾‹
        level: L1/L2/L3
    
    è¿”å›:
        DataFrame: è¡Œä¸šåˆ—è¡¨
    """
    # ä½¿ç”¨ index_basic è·å–ç”³ä¸‡æŒ‡æ•°åˆ—è¡¨
    all_df = api.call_with_retry(
        api.pro.index_basic,
        api_name="index_basic",
        market='SW'
    )
    
    if all_df is None or len(all_df) == 0:
        return None
    
    # æ ¹æ®çº§åˆ«ç­›é€‰
    if level == 'L1':
        # ä¸€çº§è¡Œä¸šï¼šä»£ç æ ¼å¼ 801xx0.SI
        df = all_df[all_df['ts_code'].str.match(r'801\d{2}0\.SI')]
        df = df[df['name'].str.contains('ç”³ä¸‡')]
        # æ’é™¤ç‰¹æ®ŠæŒ‡æ•°
        exclude_patterns = ['ç”³ä¸‡50', 'ç”³ä¸‡ä¸­å°', 'ç”³ä¸‡Aè‚¡', 'ç”³ä¸‡åˆ›ä¸š', 'ç”³ä¸‡300', 
                           'ç”³ä¸‡åˆ¶é€ ', 'ç”³ä¸‡æ¶ˆè´¹', 'ç”³ä¸‡æŠ•èµ„', 'ç”³ä¸‡æœåŠ¡', 'ç”³ä¸‡å®æº']
        for pattern in exclude_patterns:
            df = df[~df['name'].str.contains(pattern)]
    
    elif level == 'L2':
        # äºŒçº§è¡Œä¸šï¼šä»£ç æ ¼å¼ 801xxx.SI (æœ«å°¾ä¸æ˜¯0)
        df = all_df[all_df['ts_code'].str.match(r'801\d{3}\.SI')]
        df = df[~df['ts_code'].str.match(r'801\d{2}0\.SI')]  # æ’é™¤ä¸€çº§è¡Œä¸š
        df = df[df['name'].str.contains('ç”³ä¸‡')]
        # æ’é™¤éè¡Œä¸šæŒ‡æ•°
        exclude_patterns = ['ç”³ä¸‡50', 'ç”³ä¸‡ä¸­å°', 'ç”³ä¸‡Aè‚¡', 'ç”³ä¸‡åˆ›ä¸š', 'ç”³ä¸‡300', 
                           'ç”³ä¸‡å®æº', 'å¤§ç›˜æŒ‡æ•°', 'ä¸­ç›˜æŒ‡æ•°', 'å°ç›˜æŒ‡æ•°',
                           'é«˜å¸‚ç›ˆç‡', 'ä¸­å¸‚ç›ˆç‡', 'ä½å¸‚ç›ˆç‡',
                           'é«˜å¸‚å‡€ç‡', 'ä¸­å¸‚å‡€ç‡', 'ä½å¸‚å‡€ç‡',
                           'é«˜ä»·è‚¡', 'ä¸­ä»·è‚¡', 'ä½ä»·è‚¡',
                           'äºæŸè‚¡', 'å¾®åˆ©è‚¡', 'ç»©ä¼˜è‚¡',
                           'é…è‚¡æŒ‡æ•°', 'æ´»è·ƒæŒ‡æ•°', 'æ–°è‚¡æŒ‡æ•°',
                           'åŸºé‡‘é‡ä»“', 'åŸºé‡‘æ ¸å¿ƒ', 'ç”³ä¸‡é‡ç‚¹']
        for pattern in exclude_patterns:
            df = df[~df['name'].str.contains(pattern)]
        # æ’é™¤300ç³»åˆ—æŒ‡æ•°ï¼ˆå¦‚300å†œæ—ç‰§æ¸”ï¼‰
        df = df[~df['ts_code'].str.match(r'8013\d{2}\.SI')]
    
    elif level == 'L3':
        # ä¸‰çº§è¡Œä¸šï¼šä»£ç æ ¼å¼ 850xxx.SI
        df = all_df[all_df['ts_code'].str.match(r'850\d{3}\.SI')]
        df = df[df['name'].str.contains('ç”³ä¸‡')]
        # æ’é™¤éè¡Œä¸šæŒ‡æ•°
        exclude_patterns = ['ç”³ä¸‡50', 'ç”³ä¸‡ä¸­å°', 'ç”³ä¸‡Aè‚¡', 'ç”³ä¸‡åˆ›ä¸š', 'ç”³ä¸‡300', 'ç”³ä¸‡å®æº']
        for pattern in exclude_patterns:
            df = df[~df['name'].str.contains(pattern)]
    
    else:
        df = None
    
    return df.reset_index(drop=True) if df is not None else None


def get_sw_daily_data(api, ts_code, start_date, end_date):
    """
    è·å–ç”³ä¸‡è¡Œä¸šæŒ‡æ•°æ—¥è¡Œæƒ…æ•°æ®ï¼ˆåŒ…å«PE/PBï¼‰
    
    å‚æ•°:
        api: TushareAPIå®ä¾‹
        ts_code: æŒ‡æ•°ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ (YYYYMMDD)
        end_date: ç»“æŸæ—¥æœŸ (YYYYMMDD)
    
    è¿”å›:
        DataFrame: æ—¥è¡Œæƒ…æ•°æ®
    """
    df = api.call_with_retry(
        api.pro.sw_daily,
        api_name="sw_daily",
        ts_code=ts_code,
        start_date=start_date,
        end_date=end_date
    )
    
    return df


def calculate_percentile_rank(series, value):
    """è®¡ç®—æ•°å€¼åœ¨åºåˆ—ä¸­çš„å†å²ç™¾åˆ†ä½"""
    if pd.isna(value) or len(series) == 0:
        return None
    
    clean_series = series.dropna()
    if len(clean_series) == 0:
        return None
    
    count_below = (clean_series < value).sum()
    count_equal = (clean_series == value).sum()
    percentile = (count_below + 0.5 * count_equal) / len(clean_series) * 100
    
    return round(percentile, 2)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç”³ä¸‡è¡Œä¸šæŒ‡æ•°ä¼°å€¼ç™¾åˆ†ä½åˆ†æ - sw_dailyç‰ˆ')
    parser.add_argument('--years', type=int, default=1, help='å›çœ‹å†å²å¹´æ•° (é»˜è®¤1å¹´)')
    parser.add_argument('--interval', type=int, default=0, 
                        help='é‡‡æ ·é—´éš”å¤©æ•° (é»˜è®¤0è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨æ•°æ®)')
    parser.add_argument('--level', type=str, default='L1', choices=['L1', 'L2', 'L3'],
                        help='è¡Œä¸šåˆ†ç±»çº§åˆ«: L1-ä¸€çº§è¡Œä¸š, L2-äºŒçº§è¡Œä¸š, L3-ä¸‰çº§è¡Œä¸š')
    parser.add_argument('--output', '-o', type=str, default='.',
                        help='è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤å½“å‰ç›®å½•)')
    args = parser.parse_args()
    
    # åˆå§‹åŒ–
    pro = ts.pro_api(TOKEN)
    api = TushareAPI(pro)
    
    level_names = {'L1': 'ä¸€çº§è¡Œä¸š', 'L2': 'äºŒçº§è¡Œä¸š', 'L3': 'ä¸‰çº§è¡Œä¸š'}
    
    print("=" * 70)
    print("ç”³ä¸‡è¡Œä¸šæŒ‡æ•°å¸‚ç›ˆç‡å¸‚å‡€ç‡å†å²ç™¾åˆ†ä½åˆ†æ - sw_dailyç‰ˆ")
    print("=" * 70)
    print()
    print("ğŸ“Š ä½¿ç”¨æ¥å£: sw_daily (ç›´æ¥è·å–å®˜æ–¹PE/PBæ•°æ®)")
    print()
    print(f"ğŸ“… åˆ†ææ—¶é—´èŒƒå›´: æœ€è¿‘ {args.years} å¹´")
    print(f"ğŸ“Š è¡Œä¸šçº§åˆ«: {level_names[args.level]}")
    if args.interval > 0:
        print(f"ğŸ“Š é‡‡æ ·é—´éš”: æ¯{args.interval}å¤©")
    else:
        print(f"ğŸ“Š é‡‡æ ·é—´éš”: ä½¿ç”¨å…¨éƒ¨äº¤æ˜“æ—¥æ•°æ®")
    print()
    
    # è®¡ç®—æ—¥æœŸèŒƒå›´
    end_date = datetime.now().strftime('%Y%m%d')
    start_date = (datetime.now() - timedelta(days=args.years*365)).strftime('%Y%m%d')
    
    # æ­¥éª¤1ï¼šè·å–è¡Œä¸šåˆ—è¡¨
    print(f"ã€æ­¥éª¤1ã€‘è·å–ç”³ä¸‡{level_names[args.level]}åˆ—è¡¨...")
    industry_df = get_industry_list(api, args.level)
    
    if industry_df is None or len(industry_df) == 0:
        print(f"âŒ æ— æ³•è·å–ç”³ä¸‡{level_names[args.level]}åˆ—è¡¨")
        return
    
    print(f"âœ… è·å–åˆ° {len(industry_df)} ä¸ª{level_names[args.level]}")
    print(f"\n{level_names[args.level]}åˆ—è¡¨:")
    for _, row in industry_df.iterrows():
        print(f"  - {row['ts_code']}: {row['name']}")
    
    # æ­¥éª¤2ï¼šè·å–å„è¡Œä¸šPE/PBå†å²æ•°æ®
    print(f"\nã€æ­¥éª¤2ã€‘è·å–å„è¡Œä¸šPE/PBå†å²æ•°æ®...")
    
    results = []
    
    for i, row in industry_df.iterrows():
        ts_code = row['ts_code']
        name = row['name']
        
        print(f"  å¤„ç†: {name} ({ts_code})")
        
        # è·å–å†å²æ•°æ®
        df = get_sw_daily_data(api, ts_code, start_date, end_date)
        
        if df is None or len(df) == 0:
            print(f"    âš ï¸ æ— æ•°æ®")
            continue
        
        # æŒ‰æ—¥æœŸæ’åº
        df = df.sort_values('trade_date', ascending=False)
        
        # é‡‡æ ·ï¼ˆå¦‚æœæŒ‡å®šäº†é—´éš”ï¼‰
        if args.interval > 0:
            df = df.iloc[::args.interval].reset_index(drop=True)
        
        # è·å–æœ€æ–°å€¼
        latest = df.iloc[0]
        current_pe = latest['pe']
        current_pb = latest['pb']
        
        # è®¡ç®—ç™¾åˆ†ä½
        pe_percentile = calculate_percentile_rank(df['pe'], current_pe)
        pb_percentile = calculate_percentile_rank(df['pb'], current_pb)
        
        results.append({
            'index_code': ts_code,
            'index_name': name,
            'pe': round(current_pe, 2) if pd.notna(current_pe) else None,
            'pe_percentile': pe_percentile,
            'pb': round(current_pb, 2) if pd.notna(current_pb) else None,
            'pb_percentile': pb_percentile,
            'sample_count': len(df),
            'latest_date': latest['trade_date']
        })
        
        pe_str = f"{current_pe:.2f}" if pd.notna(current_pe) else "N/A"
        pb_str = f"{current_pb:.2f}" if pd.notna(current_pb) else "N/A"
        print(f"    âœ… PE={pe_str} ({pe_percentile}%), PB={pb_str} ({pb_percentile}%)")
    
    # æ­¥éª¤3ï¼šè¾“å‡ºç»“æœ
    print("\n" + "=" * 70)
    print(f"ç”³ä¸‡{level_names[args.level]}ä¼°å€¼ç™¾åˆ†ä½æ’åï¼ˆæŒ‰PEç™¾åˆ†ä½ä»ä½åˆ°é«˜ï¼‰")
    print("=" * 70)
    
    if not results:
        print("âŒ æ— æœ‰æ•ˆæ•°æ®")
        return
    
    results_df = pd.DataFrame(results)
    # æŒ‰PEç™¾åˆ†ä½å‡åºæ’åˆ—ï¼ŒNaNå€¼æ’åœ¨æœ€å
    results_df = results_df.sort_values('pe_percentile', ascending=True, na_position='last')
    
    # æ ¼å¼åŒ–è¾“å‡º
    print(f"{'æ’å':<4} {'è¡Œä¸šä»£ç ':<12} {'è¡Œä¸šåç§°':<20} {'PE':<10} {'PEç™¾åˆ†ä½':<10} {'PB':<10} {'PBç™¾åˆ†ä½':<10} {'æ•°æ®ç‚¹':<8}")
    print("-" * 90)
    
    for i, (_, row) in enumerate(results_df.iterrows(), 1):
        pe_str = f"{row['pe']:.2f}" if row['pe'] else "N/A"
        pb_str = f"{row['pb']:.2f}" if row['pb'] else "N/A"
        pe_pct_str = f"{row['pe_percentile']:.1f}%" if row['pe_percentile'] is not None else "N/A"
        pb_pct_str = f"{row['pb_percentile']:.1f}%" if row['pb_percentile'] is not None else "N/A"
        
        print(f"{i:<4} {row['index_code']:<12} {row['index_name']:<20} {pe_str:<10} {pe_pct_str:<10} {pb_str:<10} {pb_pct_str:<10} {row['sample_count']:<8}")
    
    # ä¿å­˜ç»“æœ
    output_dir = args.output
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
    
    output_file = os.path.join(output_dir, f"industry_pe_pb_sw_{args.level}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ç»“æœå·²ä¿å­˜è‡³: {output_file}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - APIæ€»è°ƒç”¨æ¬¡æ•°: {api.total_requests}")
    print(f"   - è¡Œä¸šæ•°é‡: {len(results_df)}")
    print(f"   - åˆ†æèµ·å§‹æ—¥æœŸ: {start_date}")
    print(f"   - åˆ†æç»“æŸæ—¥æœŸ: {end_date}")


if __name__ == '__main__':
    main()
